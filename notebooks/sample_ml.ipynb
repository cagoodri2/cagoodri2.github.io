{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOC5WACzwXKspO79WG8C9Jr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagoodri2/cagoodri2.github.io/blob/master/Sample_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Author: Corissa Goodrich\n",
        "\n",
        "Project: Machine Learning Analysis - Classifying Meteor Type\n",
        "\n",
        "The following code is a sample of the complete project."
      ],
      "metadata": {
        "id": "S-CILtgi4y8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning) #removal of continual future warning"
      ],
      "metadata": {
        "id": "e7oCnHkwAumJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0S_emjpp4tnC"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px #for geographic visualization\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SAMPLE FEATURE ENGINEERING\n",
        "# original dataset has 422 unique values for meteorite classification. For the purposes of this project on categorizing the four main categories of meteorite.\n",
        "a_chon = ['Iodranite', 'Acapulcoite', 'Winonaite', 'Martian','Shergottite','Chassignite','ALH 84001 opx','Nakhlites',\n",
        "          'Aubrite','Ureilite', 'HED', 'Eucrite', 'Diogenite','Howardite', 'Angrite','Brachinite',\n",
        "          'Lunar','Feldspathic Breccias', 'Basaltic','Polymict']\n",
        "meteor.loc[meteor[\"recclass\"].str.contains('Palasite'), ['types']] = 'stone'\n",
        "meteor.loc[meteor[\"recclass\"].str.contains('Mesosiderite'), ['types']] = 'stone'\n",
        "meteor.loc[meteor[\"recclass\"].str.contains('Iron'), ['types']] = 'iron'\n",
        "meteor.loc[meteor[\"recclass\"].isin(a_chon), ['types']] = 'a_chon'\n",
        "meteor.loc[meteor[\"types\"].str.contains(\" \"), ['types']] = 'chon'\n",
        "\n",
        "meteor.sample(n=25) #ran x 10 to check categorization\n",
        "\n"
      ],
      "metadata": {
        "id": "xr1ede4vALe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SAMPLE ADABOOST WITH STANDARD PARAMETERS\n",
        "adb = AdaBoostClassifier()\n",
        "adb = adb.fit(X_train, y_train)\n",
        "pred_train = adb.predict(X_train)\n",
        "pred_test = adb.predict(X_test)"
      ],
      "metadata": {
        "id": "L7-qdDPkAnVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"\\nClassification Report for Training Dataset:\")\n",
        "print(metrics.classification_report(y_train, pred_train, zero_division=1))\n",
        "print(\"\\nClassification Report for Testing Dataset:\")\n",
        "print(metrics.classification_report(y_test, pred_test,zero_division=1))"
      ],
      "metadata": {
        "id": "eXtK-w6nA97Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_train = metrics.accuracy_score(pred_train, y_train)\n",
        "a_test = metrics.accuracy_score(pred_test, y_test)\n",
        "c_train = metrics.confusion_matrix(pred_train, y_train)\n",
        "c_test = metrics.confusion_matrix(pred_test, y_test)\n",
        "f1 = metrics.f1_score(pred_test, y_test, average ='micro') #multiclass target variable, avg set to micro\n",
        "\n",
        "\n",
        "print(\"\\nAccuracy Score for Training Set: \", round(a_train,2))\n",
        "print(\"\\nAccuracy Score for Testing Set: \", round(a_test,2))\n",
        "print('\\nDifference between scores: ', round((a_train - a_test),2))\n",
        "print('\\nConfusion Matrix for the Training Set\\n', c_train)\n",
        "print('\\nConfusion Matrix for Testing Set\\n', c_test)\n",
        "print('\\nF1 Score for testing set: ', round(f1,2))"
      ],
      "metadata": {
        "id": "6noloVpCBDMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SAMPLE ADABOOST WITH GRIDSEARCH\n",
        "param = dict(learning_rate = [0.001, 0.01, 0.1, 1.0], n_estimators = [1,2,3,4,5])\n",
        "adb_grid = GridSearchCV(estimator=adb, param_grid=param, cv=10, n_jobs=-1)\n",
        "adb_grid.fit(X_train, y_train)\n",
        "adb_grid.best_params_"
      ],
      "metadata": {
        "id": "Xjj9WtEYBIx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adb_best = AdaBoostClassifier(learning_rate = 0.001, n_estimators = 1)\n",
        "adb_best = adb_best.fit(X_train, y_train)\n",
        "pred_train = adb_best.predict(X_train)\n",
        "pred_test = adb_best.predict(X_test)"
      ],
      "metadata": {
        "id": "-sgaXoX_BUHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"\\nClassification Report for Training Dataset:\")\n",
        "print(metrics.classification_report(y_train, pred_train, zero_division=1))\n",
        "print(\"\\nClassification Report for Testing Dataset:\")\n",
        "print(metrics.classification_report(y_test, pred_test,zero_division=1))"
      ],
      "metadata": {
        "id": "lA2rEHzDBYyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_train = metrics.accuracy_score(pred_train, y_train)\n",
        "a_test = metrics.accuracy_score(pred_test, y_test)\n",
        "c_train = metrics.confusion_matrix(pred_train, y_train)\n",
        "c_test = metrics.confusion_matrix(pred_test, y_test)\n",
        "f1 = metrics.f1_score(pred_test, y_test, average ='micro') #multiclass target variable, avg set to micro\n",
        "\n",
        "\n",
        "print(\"\\nAccuracy Score for Training Set: \", round(a_train,2))\n",
        "print(\"\\nAccuracy Score for Testing Set: \", round(a_test,2))\n",
        "print('\\nDifference between scores: ', round((a_train - a_test),2))\n",
        "print('\\nConfusion Matrix for the Training Set\\n', c_train)\n",
        "print('\\nConfusion Matrix for Testing Set\\n', c_test)\n",
        "print('\\nF1 Score for testing set: ', round(f1,2))"
      ],
      "metadata": {
        "id": "ofi4tJckBcP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SEABORN HEATMAP CONFUSION MATRIX\n",
        "sns.heatmap(c_test/np.sum(c_test), annot=True, cmap = 'Blues', fmt='.2%')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y1pkw57-BhN9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
